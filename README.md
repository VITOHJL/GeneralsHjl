# Generals.io - 本地单机游戏

一个基于 generals.io 游戏规则的本地单机策略游戏。玩家可以在本地与AI机器人对战，体验经典的领土扩张和策略对战玩法。

## 项目状态

✅ **已实现核心功能** - 游戏可玩，支持人机对战和AI对战

## 项目特点

- 🎮 **本地单机游戏** - 无需联网，本地运行
- 🤖 **智能AI对手** - 随机AI、自适应AI和Minimax AI（包含经典博弈算法）
- 🗺️ **随机地图生成** - 每次游戏都是新体验，支持自定义地图尺寸
- 🎯 **经典游戏规则** - 完全遵循 generals.io 的游戏规则
- 💻 **现代化技术栈** - React + Vite + Canvas + Zustand
- 🎨 **精美UI界面** - 响应式设计，支持缩放和重置视角

## 游戏规则

### 基本玩法

1. **地图**: 网格地图，包含空地、山脉、要塞和首都
2. **军队**: 每个己方格子每回合自动增长军队
3. **移动**: 从己方格子移动到相邻格子（需要至少2个军队）
4. **战斗**: 移动到敌方格子会触发战斗
5. **胜利**: 最后一个存活的玩家获胜（占领敌方首都或消灭所有敌方军队）

### 详细规则

- **军队增长**: 
  - 普通格子：每25回合（1轮）+1单位
  - 要塞：每回合+1单位
  - 首都：每回合+1单位

- **战斗机制**: 
  - 攻击方单位数 > 防御方：占领，剩余 = 攻击方 - 防御方
  - 攻击方单位数 = 防御方：双方都消失，格子变为空地
  - 攻击方单位数 < 防御方：攻击失败，防御方剩余 = 防御方 - 攻击方

- **移动规则**: 
  - 只能移动到相邻的上下左右四个方向
  - 不能移动到山区
  - 移动时必须在原格子留下至少1个单位
  - 支持两种移动方式：
    - **点击+点击**：移动50%兵力（向下取整）
    - **点击+拖拽**：只保留1个单位，其余全部移动

- **特殊格子**: 
  - **空地（Blank）**: 可占领的普通格子
  - **山脉（Mountain）**: 不可通过，不可占领
  - **要塞（Stronghold）**: 可占领，每回合+1单位，占领需要额外20-30随机人口
  - **首都（Capital）**: 玩家起始点，被占领即失败，每回合+1单位
  - **首都迁移**: 占领敌方首都时，己方首都迁移到新位置，原首都变为要塞

## 技术栈

- **React 18** - UI框架
- **Vite** - 构建工具
- **Zustand** - 状态管理
- **HTML5 Canvas** - 游戏渲染
- **Tailwind CSS** - 样式框架
- **JavaScript (ES6+)** - 游戏逻辑

## 项目结构

```
generals.io/
├── src/
│   ├── components/          # React组件
│   │   ├── GameCanvas.jsx   # 游戏画布
│   │   ├── GameMenu.jsx     # 游戏菜单
│   │   ├── GameUI.jsx       # 游戏UI（排行榜、当前玩家等）
│   │   ├── PauseMenu.jsx    # 暂停菜单
│   │   └── GameMenuModal.jsx # 游戏内菜单模态框
│   ├── game/                # 游戏核心逻辑
│   │   ├── GameEngine.js    # 游戏引擎
│   │   ├── MapGenerator.js  # 地图生成器
│   │   ├── Renderer.js      # 渲染引擎
│   │   └── ai/              # AI系统
│   │       ├── AIBase.js    # AI基类
│   │       ├── RandomAI.js  # 随机AI
│   │       ├── AdaptiveAI.js # 自适应AI（智能策略）
│   │       └── index.js     # AI导出
│   ├── training/            # AI训练和评估系统
│   │   ├── train.js         # 命令行工具
│   │   ├── GameSimulator.js # 游戏模拟器
│   │   ├── Evaluator.js     # 评估器
│   │   ├── README.md        # 训练系统文档
│   │   ├── COMMANDS.md      # 命令详解
│   │   └── METRICS.md       # 评估指标说明
│   ├── store/               # 状态管理
│   │   └── gameStore.js    # 游戏状态存储
│   ├── utils/               # 工具函数
│   │   └── colors.js        # 颜色配置
│   ├── assets/              # 资源文件
│   │   └── tiles/           # 格子图片
│   ├── App.jsx              # 主应用组件
│   └── main.jsx             # 入口文件
├── package.json
├── vite.config.js
├── tailwind.config.js
└── README.md
```

## 安装和运行

### 环境要求

- Node.js 16+ 
- npm 或 yarn

### 安装依赖

```bash
npm install
```

### 开发模式

```bash
npm run dev
```

开发服务器将在 `http://localhost:1732` 启动（支持 `--host` 参数，可在局域网访问）

### 构建生产版本

```bash
npm run build
```

### 预览生产版本

```bash
npm run preview
```

## 功能特性

### 已实现功能

#### AI训练和评估系统
- [x] **游戏模拟器** - 无头模式运行游戏，收集统计数据
- [x] **多维度评估器** - 评估AI的胜负、效率、稳定性等指标
- [x] **命令行工具** - 支持evaluate、compare、benchmark三种命令
- [x] **数据集分离** - 训练集、验证集、测试集分离
- [x] **对抗性测试** - 被围攻、资源劣势、长期对抗等场景
- [x] **稳定性评估** - 标准差、变异系数、分位数分析
- [x] **场景覆盖** - 支持不同地图尺寸、玩家数量、对手类型

#### 核心游戏功能
- [x] **公平地图生成系统**（支持小/中/大三种尺寸）
  - Voronoi图算法确保各玩家初始地盘大小差异 < 20%
  - 首都之间最小距离 = WIDTH * 0.4（曼哈顿距离）
  - 区域内资源（要塞、山区）均衡分配
  - 连通性保证（允许最多20%不连通）
- [x] 回合制游戏引擎
- [x] 军队增长系统
- [x] 战斗系统
- [x] 占领系统
- [x] 胜利判定（最后存活者获胜）
- [x] 首都迁移机制
- [x] 要塞占领机制（需要额外人口）

#### 玩家操作
- [x] 点击选择源格子
- [x] 点击目标格子移动（50%兵力）
- [x] 拖拽移动（保留1个单位，其余全部移动）
- [x] 操作验证和反馈
- [x] 高亮显示选中格子
- [x] 显示移动预览

#### AI系统
- [x] **RandomAI** - 随机移动AI（基础难度）
- [x] **AdaptiveAI** - 自适应AI（智能策略）
  - 进攻策略：根据兵力对比、距离、威胁等因素选择进攻目标
  - 防御策略：保护重要目标（首都、要塞）
  - 发育策略：扩张领土、占领要塞、模仿敌方扩张
  - 策略权重：进攻(1.25) > 防御(1.1) > 发育(0.95)
- [x] **MinimaxAI** - Minimax算法AI（博弈树搜索）
  - 使用Minimax算法和Alpha-Beta剪枝进行决策
  - 多维度评估函数：领土、军队、重要目标、增长率、位置优势
  - 可配置搜索深度和分支数（默认深度2层，每层最多10个分支）
  - 适合人工智能课程学习和研究

#### UI界面
- [x] 游戏主菜单（配置玩家、地图尺寸、AI类型）
- [x] 游戏画布（Canvas渲染）
- [x] 游戏UI（当前玩家、回合数、排行榜）
- [x] 暂停菜单（退出游戏）
- [x] 缩放和重置视角功能
- [x] 玩家颜色系统（每个玩家固定颜色）
- [x] 当前玩家高亮边框
- [x] 响应式设计

#### 游戏配置
- [x] 支持2-8个玩家
- [x] 每个玩家可配置为人或AI
- [x] AI类型选择（Random、Adaptive、Minimax）
- [x] 地图尺寸选择（小15x15、中25x25、大35x35）

### 计划实现

- [ ] 游戏回放功能
- [ ] 统计信息（胜率、平均回合数等）
- [ ] 快捷键支持
- [ ] 音效和背景音乐
- [ ] 更多AI策略类型
- [ ] 迷雾系统（视野限制）
- [ ] 任务队列系统（半回合制）

## 地图生成系统详解

### 公平地图生成算法

地图生成采用**公平优先**的设计理念，确保所有玩家在游戏开始时拥有相对均衡的起始条件。

#### 生成流程

1. **Voronoi图确认首都位置**
   - 首都之间最小距离：`WIDTH * 0.4`（曼哈顿距离）
   - 迭代优化：最多尝试50次，找到满足平衡条件的配置
   - 平衡条件：各玩家初始地盘大小差异 < 20%

2. **区域划分（Voronoi图）**
   - 根据最近距离原则，将地图划分为各玩家的"势力范围"
   - 每个格子归属距离最近的首都
   - 确保每个玩家有明确的初始地盘

3. **区域内要塞分配**
   - 每个区域的要塞数量：随机范围 `[(width*height)/(playerCount*30), (width*height)/(playerCount*20)]`
   - 从各区域的空地中随机选择位置
   - 确保每个玩家都有相对均衡的要塞资源

4. **区域内山区分配（注意连通性）**
   - 每个区域的山区数量：随机范围 `[(width*height)/(playerCount*8), (width*height)/(playerCount*6)]`
   - 放置时实时检查连通性（允许最多20%不连通）
   - 避免在首都直接相邻位置放置山区
   - 如果连通性检查太严格，至少放置目标数量的70%

5. **最终连通性检查**
   - 使用BFS算法检查整体地图连通性
   - 如果发现不连通，智能移除部分山区

#### 公平性保证

- ✅ **地盘大小均衡**：各玩家初始地盘大小差异 < 20%
- ✅ **资源分布均衡**：每个区域的要塞和山区数量在随机范围内，相对均衡
- ✅ **距离控制**：首都之间距离合理，避免开局冲突
- ✅ **连通性保证**：确保玩家可以互相到达，但允许一定程度的隔离（20%）

#### 可调整参数

在 `MapGenerator.js` 中可以调整：

- **要塞数量范围**：
  - `minStrongholdsPerRegion`: `(width*height)/(playerCount*30)`
  - `maxStrongholdsPerRegion`: `(width*height)/(playerCount*20)`

- **山区数量范围**：
  - `minMountainsPerRegion`: `(width*height)/(playerCount*8)`
  - `maxMountainsPerRegion`: `(width*height)/(playerCount*6)`

- **连通性阈值**：
  - 当前设置为80%（允许20%不连通）

## AI系统详解

### RandomAI（随机AI）

最简单的AI，随机选择己方格子向随机方向移动。适合新手练习。

### MinimaxAI（Minimax算法AI）

基于经典Minimax算法和Alpha-Beta剪枝的AI，适合人工智能课程学习和研究。

#### 算法特点

- **Minimax算法**：在博弈树中搜索最优决策
  - 最大化层（己方）：选择得分最高的移动
  - 最小化层（对手）：假设对手选择对己方最不利的移动
- **Alpha-Beta剪枝**：优化搜索效率，剪除不可能影响最终决策的分支
- **可配置参数**：
  - `maxDepth`：搜索深度（默认2层，建议2-3层）
  - `maxBranches`：每层最大分支数（默认10个，限制搜索空间）

#### 评估函数（启发式）

评估函数从多个维度评估游戏状态，返回对己方有利的分数：

1. **领土优势**（权重30%）：己方领土数量 vs 对手平均领土数量
2. **军队优势**（权重25%）：己方总兵力 vs 对手平均总兵力
3. **重要目标控制**（权重20%）：首都（100分/个）+ 要塞（50分/个）
4. **军队增长率**（权重15%）：每回合军队增长潜力
5. **位置优势**（权重10%）：己方首都到敌方首都的距离（距离越近越好）

#### 性能优化

- **深度限制**：默认搜索2层，避免计算时间过长
- **分支剪枝**：每层只考虑最有希望的10个移动（按启发式分数排序）
- **状态模拟**：使用深度复制模拟移动，不影响实际游戏状态
- **回退机制**：如果Minimax失败，自动回退到RandomAI

#### 适用场景

- 人工智能课程教学
- 博弈算法研究
- 小规模对战（2-4玩家，搜索深度2-3层）
- 需要精确决策的场景

**注意**：MinimaxAI的计算复杂度较高，在多人游戏或大地图中可能较慢。建议：
- 2-3玩家：深度2-3层
- 4+玩家：深度1-2层
- 大地图：减少maxBranches或降低深度

### AdaptiveAI（自适应AI）

智能AI系统，采用多策略评估机制：

#### 策略评估流程

1. **构建上下文**：分析当前游戏状态
   - 己方/敌方格子分布
   - 重要目标位置（首都、要塞）
   - 兵力对比
   - 威胁检测

2. **生成策略候选**：
   - **进攻策略**：评估进攻敌方重要目标的可行性
   - **防御策略**：评估保护己方重要目标的必要性
   - **发育策略**：评估扩张领土的优先级

3. **评分和选择**：
   - 每个策略计算基础分数
   - 应用策略权重（进攻1.25、防御1.1、发育0.95）
   - 选择得分最高的策略执行
   - 如果所有策略得分≤0，回退到RandomAI

#### 进攻策略触发条件

- **保守型**：己方总兵力明显领先时进攻
- **激进型**：己方首都兵力≥敌方首都兵力时进攻
- **反击型**：己方重要目标被威胁时优先打击威胁来源
- **孤注一掷**：50回合后仍落后时提高进攻倾向

#### 防御策略

- 检测己方首都/要塞附近的敌方单位
- 从最近的己方格子调兵支援
- 重要性越高（首都>要塞），防御优先级越高

#### 发育策略（四种模式随机切换）

- **最近要塞**（35%概率）：优先占领最近的中立要塞
- **边界扩张**（30%概率）：向己方边界外的空地扩张
- **进攻型发育**（20%概率）：针对敌方重要目标定向扩张
- **模仿型**（15%概率）：沿敌方主要推进方向扩张

## AI训练和评估系统

### 概述

项目包含完整的AI训练和评估框架，用于测试和优化AI性能。系统采用多维度评估、数据集分离、对抗性测试等方法，避免过拟合问题。

### 核心设计理念

- **多维度评估**：不只看胜率，还评估效率、稳定性等指标
- **数据集分离**：训练集（基础场景）、验证集（对抗性测试）、测试集（边界情况）
- **对抗性测试**：模拟真实对抗场景（被围攻、资源劣势、长期对抗）
- **稳定性评估**：通过标准差、变异系数、分位数评估表现稳定性

### 快速开始

**⚠️ 注意：所有参数都是必需的，必须完整提供**

#### Bash / Linux / macOS

```bash
# 评估adaptive AI
npm run train:evaluate -- \
  --ai adaptive \
  --games 50 \
  --validation 50 \
  --against random \
  --mapSizes 10x10,15x15 \
  --players 2,3,4,5,6 \
  --maxTurns 1500 \
  --maxTime 30000

# 对比两个AI
npm run train:compare -- \
  --ai1 adaptive \
  --ai2 random \
  --games 50 \
  --width 25 \
  --height 25 \
  --maxTurns 500 \
  --maxTime 30000

# 基准测试所有AI
npm run train:benchmark -- \
  --all \
  --games 50 \
  --validation 25 \
  --against random \
  --mapSizes 20x20,30x30 \
  --players 2,3 \
  --maxTurns 500 \
  --maxTime 30000
```

#### PowerShell / Windows

**推荐使用单行命令：**

```powershell
# 评估adaptive AI
node src/training/train.js evaluate --ai adaptive --games 50 --validation 50 --against random --mapSizes 10x10,15x15 --players 2,3,4,5,6 --maxTurns 1500 --maxTime 30000

# 对比两个AI
node src/training/train.js compare --ai1 adaptive --ai2 random --games 50 --width 25 --height 25 --maxTurns 500 --maxTime 30000

# 基准测试所有AI
node src/training/train.js benchmark --all --games 50 --validation 25 --against random --mapSizes 20x20,30x30 --players 2,3 --maxTurns 500 --maxTime 30000
```

**或使用反引号作为行继续符：**

```powershell
# 评估adaptive AI
node src/training/train.js evaluate `
  --ai adaptive `
  --games 50 `
  --validation 50 `
  --against random `
  --mapSizes 10x10,15x15 `
  --players 2,3,4,5,6 `
  --maxTurns 1500 `
  --maxTime 30000
```

### 命令说明

#### evaluate - 评估单个AI

对单个AI进行多维度、多层次的全面评估，包括基础场景、对抗性测试、边界情况等。

**必需参数：**
- `--ai`: AI类型（如：adaptive, random）
- `--games`: 每个基础场景的游戏数量
- `--validation`: 每个对抗性场景的游戏数量
- `--against`: 对手AI类型（逗号分隔，如：random,adaptive）
- `--mapSizes`: 地图尺寸（格式：`10x10,15x15`）
- `--players`: 玩家数量（逗号分隔，如：`2,3,4,5,6`）
- `--maxTurns`: 最大回合数
- `--maxTime`: 超时时间（毫秒）

**可选参数：**
- `--output`: 保存结果到JSON文件
- `--verbose`: 详细输出
- `--quiet`: 静默模式

#### compare - 对比两个AI

直接对比两个AI在相同配置下的对战表现。

**必需参数：**
- `--ai1`: 第一个AI类型（玩家1）
- `--ai2`: 第二个AI类型（玩家2）
- `--games`: 对战游戏数量
- `--width`: 地图宽度
- `--height`: 地图高度
- `--maxTurns`: 最大回合数
- `--maxTime`: 超时时间（毫秒）

#### benchmark - 基准测试所有AI

对所有AI进行基准测试并排名。

**必需参数：**
- `--all` 或 `--ais`: AI列表（`--all` 测试所有AI，`--ais` 指定AI列表，逗号分隔）
- `--games`: 每个AI的测试游戏数量
- `--validation`: 每个AI的验证游戏数量
- `--against`: 对手AI类型（逗号分隔）
- `--mapSizes`: 地图尺寸（格式：`20x20,30x30`）
- `--players`: 玩家数量（逗号分隔）
- `--maxTurns`: 最大回合数
- `--maxTime`: 超时时间（毫秒）

### 评估指标

系统会评估以下指标：

- **胜负指标**：胜率、存活率
- **效率指标**：每回合移动数、单位利用率
- **稳定性指标**：标准差、变异系数、分位数（P25/P75/P95）
- **场景覆盖**：不同地图尺寸、玩家数量、对手类型

### 详细文档

**📖 完整训练系统文档请查看：[src/training/README.md](./src/training/README.md)**

**📖 命令详解请查看：[src/training/COMMANDS.md](./src/training/COMMANDS.md)**

**📖 评估指标说明请查看：[src/training/METRICS.md](./src/training/METRICS.md)**

## 游戏截图

（可在此处添加游戏截图）

## 开发计划

详细开发计划请查看 [PROJECT_PLAN.md](./PROJECT_PLAN.md)

## 贡献

欢迎提交 Issue 和 Pull Request！

## License

MIT

## 参考资料

- [Generals.io 官方网站](https://generals.io)
- [Generals.io 游戏规则](https://generals.io/help)

---

**注意**: 这是一个独立开发的游戏项目，与官方的 generals.io 无关。
